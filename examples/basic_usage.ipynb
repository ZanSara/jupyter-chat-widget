{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jupyter-chat-widget\n",
    "\n",
    "This notebook demonstrates how to use the `jupyter-chat-widget` package to create interactive chat interfaces in Jupyter notebooks.\n",
    "\n",
    "---\n",
    "\n",
    "PyPI: [jupyter-chat-widget](https://pypi.org/project/jupyter-chat-widget/)\n",
    "\n",
    "GitHub: [jupyter-chat-widget](https://github.com/ZanSara/jupyter-chat-widget)\n",
    "\n",
    "Maintainer: [ZanSara](https://zansara.dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "If you haven't installed the package yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter-chat-widget in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (0.1.0)\n",
      "Requirement already satisfied: ipywidgets>=8.0.0 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from jupyter-chat-widget) (8.1.8)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from ipywidgets>=8.0.0->jupyter-chat-widget) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from ipywidgets>=8.0.0->jupyter-chat-widget) (9.9.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from ipywidgets>=8.0.0->jupyter-chat-widget) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from ipywidgets>=8.0.0->jupyter-chat-widget) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from ipywidgets>=8.0.0->jupyter-chat-widget) (3.0.16)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->jupyter-chat-widget) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->jupyter-chat-widget) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->jupyter-chat-widget) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->jupyter-chat-widget) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->jupyter-chat-widget) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->jupyter-chat-widget) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->jupyter-chat-widget) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->jupyter-chat-widget) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets>=8.0.0->jupyter-chat-widget) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.0->jupyter-chat-widget) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets>=8.0.0->jupyter-chat-widget) (0.2.14)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets>=8.0.0->jupyter-chat-widget) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets>=8.0.0->jupyter-chat-widget) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in /home/s/Projects/jupyter-chat/.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets>=8.0.0->jupyter-chat-widget) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install jupyter-chat-widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup\n",
    "\n",
    "Import the `ChatUI` class and create an instance. This will immediately display a usable chat interface, but the assistant won't respond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ddc34f9a224c368bbc2ac5751eccb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6164f0f84464c4181ea13ff6a737fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e3c826b9194705b6117018fde62458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='user: ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from jupyter_chat_widget import ChatUI\n",
    "\n",
    "chat = ChatUI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Echo Handler\n",
    "\n",
    "Connect a callback function that will be called whenever the user submits a message. This simple example echoes back the user's message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0890c3df5f4a6c94e7f42e81e7ad01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76927baf8b9145169df36d320c92cc5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9256ad92654e7c910c6842a0dcc4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='user: ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = ChatUI()\n",
    "\n",
    "def echo_handler(message: str) -> None:\n",
    "    \"\"\"Echo back the user's message.\"\"\"\n",
    "    chat.rewrite(f\"You said: {message}\")\n",
    "\n",
    "chat.connect(echo_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try typing a message in the input field above and pressing Enter!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Responses\n",
    "\n",
    "The `append()` method allows you to stream responses token by token, which is perfect for simulating or displaying LLM output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "# Create a new chat for this demo\n",
    "streaming_chat = ChatUI()\n",
    "\n",
    "def streaming_handler(message: str) -> None:\n",
    "    \"\"\"Echo back the message word by word with a delay.\"\"\"\n",
    "    words = message.split()\n",
    "    for i, word in enumerate(words):\n",
    "        sleep(0.3)  # Simulate processing time\n",
    "        streaming_chat.append(word)\n",
    "        if i < len(words) - 1:\n",
    "            streaming_chat.append(\" \")\n",
    "\n",
    "streaming_chat.connect(streaming_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using rewrite() for Final Formatting\n",
    "\n",
    "You can combine `append()` for streaming and `rewrite()` for final formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_chat = ChatUI()\n",
    "\n",
    "def combined_handler(message: str) -> None:\n",
    "    \"\"\"Stream the response, then format it nicely.\"\"\"\n",
    "    # First, stream the processing\n",
    "    combined_chat.append(\"Processing\")\n",
    "    for _ in range(3):\n",
    "        sleep(0.5)\n",
    "        combined_chat.append(\".\")\n",
    "    \n",
    "    sleep(0.5)\n",
    "    \n",
    "    # Then rewrite with the final response\n",
    "    word_count = len(message.split())\n",
    "    char_count = len(message)\n",
    "    combined_chat.rewrite(\n",
    "        f\"Analysis complete! Your message has {word_count} words and {char_count} characters.\"\n",
    "    )\n",
    "\n",
    "combined_chat.connect(combined_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clearing the Chat\n",
    "\n",
    "Use `clear()` to reset the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clear a chat\n",
    "# chat.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with LLMs\n",
    "\n",
    "Here's a template for integrating with an LLM API. Replace the placeholder with your actual LLM client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Integration template (not functional - requires your LLM client)\n",
    "\n",
    "llm_chat = ChatUI()\n",
    "\n",
    "def llm_handler(message: str) -> None:\n",
    "    \"\"\"Handle messages with an LLM.\"\"\"\n",
    "    # Replace this with your actual LLM integration\n",
    "    # Example with a hypothetical streaming API:\n",
    "    #\n",
    "    # for token in llm_client.stream(message):\n",
    "    #     llm_chat.append(token)\n",
    "    \n",
    "    # Placeholder response\n",
    "    llm_chat.rewrite(\"[LLM integration placeholder - replace with your API call]\")\n",
    "\n",
    "llm_chat.connect(llm_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Summary\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `ChatUI()` | Create a new chat widget |\n",
    "| `connect(callback)` | Set the message handler |\n",
    "| `append(token)` | Add text to current response |\n",
    "| `rewrite(text)` | Replace entire response |\n",
    "| `clear()` | Clear chat history |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
